{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Discourse\n",
    "\n",
    "### **Finding Numerical Ratings of Consumer Sentiments using GTE Sentence Transformers**\n",
    "\n",
    "by Vinicius Ambrosi, Gilyoung Cheong, Dohoon Kim, Hannah Lloyd\n",
    "\n",
    "**Abstract**. There is a wealth of discourse on companies and their products on social media platforms and online forums. While many approaches leverage analytical techniques to gauge audience sentiment through online discourse, they lack the ability to be both targeted and customizable while maintaining complex analytical integrity. In this report, we use Sentence Transformers, a state-of-art text embedding API, with GTE (General Text Embeddings with Multi-stage Contrastive Learning) pre-trained model, to vectorize 788,766 comments from Google Reviews into 1024-dimensional vectors. We then use these vectors as features to train our models and develop rating models that rate a given comment from 1 to 5 stars. Each vector provides 1024 features for a review comment, with the target variable being the rating. We develope our models using logistic regression (one vs. rest), k-nearest neighbor, suppor vector machine, XGBoost, and neural networks with a simple architecture after appropriate train-test splits. To address the biased nature of the training data, which favors 4 or 5-star ratings, we also build our model with random undersampling. With or without undersampling, we significantly improve the baseline model, which always predicts 5 stars. Our experiemental results provide how to use pre-trained Sentence Transformers to extract numerical values of consumer sentiments from online comments without the extra cost of pre-training. To corroborate our results, we demonstrate that our best-performing model performs well in predicting the ratings of reviews for the same business from a website other than Google Reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S1.$ Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online comments and reviews have grown increasingly vital in shaping consumer decisions, particularly in the aftermath of the COVID-19 pandemic. Numerous studies, including [[1]](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.865702/full), [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), [[8]](https://ieeexplore.ieee.org/document/8970492), [[9]](https://www.sciencedirect.com/science/article/pii/S0747563210000907), [[10]](https://ieeexplore.ieee.org/document/8631160), and [[11]](https://www.sciencedirect.com/science/article/abs/pii/S1567422320300570), have underscored the significance of analyzing consumer sentiments within the realms of e-commerce and tourism. The importance of these sentiments has been highlighted, showing that understanding consumer feedback can provide valuable insights into market trends and customer preferences. In light of these findings, this report utilizes natural language processing (NLP) and machine learning (ML) techniques to construct predictive models capable of assessing and rating comments provided by consumers. By employing these advanced analytical methods, we aim to enhance the correctness and effectiveness of sentiment analysis in understanding and forecasting consumer behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. NLP Methodology: GTE Sentence Transformers**. We use Sentence Transformers, a state-of-the-art text embedding NLP, to vectorize 788,766 pre-processed comments from Google Reviews about a specific business (Costco). These vectors then serve as input features for building predictive models for ratings. The pre-trained model for our sentence transformer is GTE (General Text Embeddings with Multi-stage Contrastive Learning) developed by Alibaba Group NLP team in [[5]](https://arxiv.org/abs/2308.03281). The earliest Sentence Transfomer, called \"Sentence-BERT,\" was developed in [[6]](https://arxiv.org/abs/1908.10084) by Reimers and Gurebych and is based on Bidirectional Encoder Representations from Transformers (BERT), introduced in [[2]](https://arxiv.org/abs/1810.04805) by Google.\n",
    "\n",
    "BERT was revolutionary because it provided vector representations of sentences, with each subword token encoded into a vector that retains its relationship with the entire input context. This contextual awareness enabled BERT to excel in tasks such as question answering, where it generates answers based on user-provided context. \n",
    "\n",
    "However, using BERT for sentence clustering posed challenges because it required providing the full context every time a sentence was vectorized. This limitation made BERT less suitable for building predictive models that needed to be tested on unknown data. Additionally, since BERT encodes each subword of a sentence into a vector, a sentence corresponds to a sequence of vectors, not a single vector, which requires significant storage. Various attempts to address these issues involved encoding each sentence without context and using either the encoded vector of the first special token (called the [CLS] token) or the average vector of the sequence of encoded vectors of all the subwords, but these approaches generally led to poor performance.\n",
    "\n",
    "Sentence Transformers uses specific loss functions to train the average BERT-generated vector of subwords of each sentence in the training set so that two semantically similar sentences are associated with two vectors that are close to each other in terms of (Euclidean) distance and angle, the latter of which is measured by cosine similarity. The details of the pre-training and fine-tuning processes of GTE Sentence Transformers are available in Section 3 of [[5]](https://arxiv.org/abs/2308.03281)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. ML Methodology: Logistic Regression, kNN, XGBoost, and FNN**. We use several widely accessible machine learning (ML) models to train on the vectors we get from GTE Sentence Transformers on our data so that they can rate a given online comment from 1 to 5 stars to capture consumers' sentiments. Specifically, we use logistic regression, k-nearest neighbor (kNN), support vector machine (SVM), XGBoost, and feedforward neural network (FNN) with three hidden layers and ReLU activation to build our models.\n",
    "\n",
    "**1.3. Data and Variables**. We use [2021 Google Review data](https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/) collected by Li and Zhang for their papers [[4]](https://aclanthology.org/2022.acl-long.426.pdf) and [[7]](https://dl.acm.org/doi/abs/10.1145/3539618.3592036). During our pre-processing, using the Google Maps ID attached to each data point, we extracted 788,766 reviews for Costco from consumers in the United States. We use GTE Sentence Transformers to construct a unique vector for each review comment in $\\mathbb{R}^{1024}$, the 1024-dimensional real vector space. Each component of such a vector is used as an input feature for each comment, so a comment has 1024 input features. The target variable is the rating, which is an integer in $\\{1, 2, 3, 4, 5\\}$. The following is the scatter plot of our training set, which is 80% of our data, projected on the first and second principal components:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/PCA picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "For building our models, we first separate the training set with test set with a ratio of 8:2. Within the training set, we apply a 11-fold cross validation for each ML method when we build our models. (For FNN, the 11-fold cross validation is simplified to a 10:1 train-test split.)\n",
    "\n",
    "**1.4. Key Contribution**. Our key contribution is to showcase how the imbalanced nature of our data influences various accssible ML models we use in the predictive analysis for consumer sentiments when it comes to online reviews. Focusing on the accuracy alone is misleading because our data is highly imbalanced. The following is the histogram for ratings in our testing set:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/Imbalance picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Thus, for each predictive modeling, we also build an additional model after random undersampling. As the reader may expect, the overall accuracy drops, but we still get a better cross-validation and the confusion matrix is much more convincing.\n",
    "\n",
    "**1.5. Comparing with Preceding Works**. There have been great interests in analyzing consumers' sentiment, many of which are surveyed by Yang, Li, Wang, and Sherratt in Section II of [[8]](https://ieeexplore.ieee.org/document/8970492). In Section III of their paper, the authors also develop their own sentiment analysis model by manually identifying (sub)words with positive and negative sentiments to create weights attached to BERT-generated vectors from the comments they pre-train. Then they apply convolutional neural network (CNN) and a modified version of recurrent neural network (RNN) to modify vectors so that they are ideally infludenced by a few words with stong sentiment and remember relationships between words. After that, they apply another linear layer with hyperbolic tangent activation followed by a SoftMax to get a numerical value between 0 and 1. Then the authors of [[8]](https://ieeexplore.ieee.org/document/8970492) use a real-world data set (in Chinese) with rating to compare their model with the true rating. Their classification is binary by classifying 1 and 2 starts to be positive while 3, 4, and 5 stars to be negative. On the other hand, our approach is greatly simplified thanks to Sentence Transformers, which cuts the pre-training step, and this can be a significant reduction in cost for deployment. \n",
    "\n",
    "In [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), Kim, Lee, Lim, Kim, and Hong also used Senternce Transformers to rank the top tourist spots in Busan, South Korea, by measuring cosine similairties between a vector generated by a given query sentence (e.g., \"It is a beautiful beach\") to the vectors generated from online review comments. Two major differences are that\n",
    "\n",
    "1. Kim et al used the model [\"all-MiniLM-L6-v2\"](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) for the sentence transformer, while we use GTE: [\"thenlper/gte-large\"](https://huggingface.co/thenlper/gte-large);\n",
    "2. the input features for Kim et al are generated by the cosine similarities between the comment vectors and a given query vector, while we directly use components of the comment vectors as our input features so that no information is possibly lost after vectorization.\n",
    "\n",
    "In either work above, the issue for the imbalance in data is not addressed. Overall, dealing with the imbalanced issue with consumer sentiment analysis is not sufficiently addressed in the literature when pertaining to consumer sentiment analysis, despite it being a common issue in data science. This was a major motivation for our investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S2$. Summary of Results\n",
    "\n",
    "**2.1. Evaluation Metrics: Accuracy, Cross Entrophy, and Normalized Correlation**. We use accuracy and cross entropy for evaluation metrics. We also use a metric we call the **normalized correlation** for a confusion matrix normalized over the true values. Specifically, if $A$ is a $n \\times n$ normalized confusion matrix whose $(i,j)$-th entry is $a_{ij}$, then its normalized correlation is defined as\n",
    "\n",
    "$$\\dfrac{N \\displaystyle\\sum_{1 \\leq i,j \\leq n}ija_{ij} - \\left(\\sum_{1 \\leq i, j \\leq n}  i a_{ij}\\right)\\left(\\sum_{1 \\leq i, j \\leq n}  j a_{ij}\\right)}{\\left(N\\displaystyle\\sum_{1 \\leq i, j \\leq n}  i^2 a_{ij} - \\left(\\sum_{1 \\leq i, j \\leq n}  i a_{ij}\\right)^2\\right)^{1/2} \\left(N\\displaystyle\\sum_{1 \\leq i, j \\leq n}  j^2 a_{ij} - \\left(\\sum_{1 \\leq i,j \\leq n}  j a_{ij}\\right)^2\\right)^{1/2}},$$\n",
    "\n",
    "where $N = \\sum_{i,j}a_{ij}$. If we apply the above formula to a non-normalized $n \\times n$ confusion matrix, we get precisely the [Pearson Product Moment Correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) between the prediction and the truth values. The normalized correlation is another measure for classification that does not suffer from imbalanced data, and a perfect prediction model admits the maximum normalized correlation of $1$. Note that for a normalized confusion matrix, we have $n = N$ and in this paper, $n = 5$.\n",
    "\n",
    "**Remark**. The normalized correlation is a robust way to measure how diagonal a matrix (with positive entries) is. More precisely, let $O$ be the zero matrix of size $n\\times n$, and let $I$ and $J$ be random variables with sample space $\\{1,2,3,4,5\\}.$ We then construct a matrix $A$ from $O$ recursively as follows: we generate outcomes $i$ and $j$ from $I$ and $J$ respectively, and increase the $(i,j)$-th entry by $1.$ Then the matrix entries tend to be near the diagonal if $I$ and $J$ are strongly correlated. Our normalized correlation is precisely the correlation of the random variables $I$ and $J.$ Note that the normalized correlation is invariant under scaling the entire matrix, i.e. $A$ and $cA$ have the same normalized correlation for any positive real number $c$, so this interpretation extends naturally to matrices with positive real entries.\n",
    "\n",
    "**Note**. From now on, **correlation** will mean the normalized correlation.\n",
    "\n",
    "For an equally probable rating prediction, if our test data is perfectly balanced, we get:\n",
    "\n",
    "* Accuracy: $0.2$\n",
    "\n",
    "* Cross Entropy: $-\\log(0.2) \\approx 1.609$\n",
    "\n",
    "* Correlation: $0$.\n",
    "\n",
    "However, since our data is *highly imbalacned* and concentrated at 5 star ratings, the reader must note that even if we consider a model that always predicts 5 star rating for every comment, we get high accuracy, which is equal to the proportion of 5 star ratings. We consider this as our baseline model. The following are the metrics for our <u>baseline</u>:\n",
    "\n",
    "* Accuracy: $0.6694$\n",
    "\n",
    "* Cross Entropy: $1.0877$\n",
    "\n",
    "* Correlation: Undefined (simply because we are forced to divide by zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The following table compares the results before random undersampling:\n",
    "\n",
    "| No Undersampling | baseline | log reg |   kNN  | XGBoost |   FNN  |\n",
    "|:----------------:|:--------:|:-------:|:------:|:-------:|:------:|\n",
    "|     Accuracy     |  0.6694  | 0.7410  | 0.7347 | 0.7402 | 0.7386 |\n",
    "|   Cross Entropy  |  1.0877  | 0.6569  | 0.8564 | 0.6532 | 0.6515 |\n",
    "|   Correlation  |  undefined  | 0.6656 | 0.7418 | 0.7483 | 0.7693 |\n",
    "\n",
    "**Remark**. kNN is with 50 neighbors and PCA with 16 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The following table compares the results <u>after random undersampling</u>:\n",
    "\n",
    "| Random Undersampling | baseline | log reg |   kNN  |   SVM  | XGBoost |   FNN  |\n",
    "|:--------------------:|:--------:|:-------:|:------:|:------:|:-------:|:------:|\n",
    "|       Accuracy       |  0.6694  |  0.6500 | 0.6315 | 0.6389 |  0.6130 | 0.6455 |\n",
    "|     Cross Entropy    |  1.0877  |  0.9101 | 0.9790 | 0.8823 |  0.9196 | 0.9823 |\n",
    "|   Correlation  |  undefined  | 0.8198 | 0.7924 | 0.8144 | 0.7968 | 0.8085  |\n",
    "\n",
    "**Remark**. kNN is with 200 neighbors and PCA with 128 components; SVM is with rbf kernal and PCA with 128 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**2.2. Best Performance: Logistic Regression**. To our surprise, <u>logistic regression showed the best performance</u> before and after random undersampling. This is good news in practice because logistic regression takes minimal computational cost among all the approaches we took. For a future project, it would be interesting to investigate for another ML algorithm or a neural network architechture that generates a better performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. Normalized Correlation and Imbalance in Data**. The following are confusion matrices for our two Logistic Regression models trained with imbalanced data and with perfectly balanced data (i.e., after random undersampling) tested on the 20% test set, which is similarly imbalanced:\n",
    "\n",
    "| Logistic Regression | No Undersampling | Random Undersampling | \n",
    "|:--------------------:|:--------:|:-------:|\n",
    "|       Confusion Matrix      | <img src=\"images/LogisticRegression_ovr_liblinear_NoneType_final.png\" width=\"80%\"></img> |  <img src=\"images/LogisticRegression_ovr_liblinear_RandomUnderSampler_final.png\" width=\"80%\"></img> |\n",
    "| Accuracy | 0.7410 | 0.6500 |\n",
    "| Cross Entropy | 0.6569 | 0.9101 |\n",
    "| Correlation | 0.6656 | 0.8198 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that even though our accuracy is lower, the confusion matrix on the right is a more reasonable prediction for the 5-class rating problem because the one on the left performs extremely poorly on 2 star ratings, and quite poorly on 3 star and 4 star ratings in comparison. This suggests that the normalized correlation is a more reasonable evaluation metric for the multi-class classification problem with imbalanced training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4. Performance on Other Rating Data**. We also test our best perfoming model (Logistic Regression) on the rating data that we scraped from Costco's website, which is an entirely different source from our training data (i.e., Google Reviews). These are 8,621 review comments with ratings. We use the same model that was built before without extra training, and we vectorize all 8,621 comments to use them as extra test data.\n",
    "\n",
    "| Testing on New Data | No Undersampling | Random Undersampling | \n",
    "|:--------------------:|:--------:|:-------:|\n",
    "|       Confusion Matrix      | <img src=\"images/LogisticRegression_ovr_liblinear_NoneType_costco.png\" width=\"80%\"></img> |  <img src=\"images/LogisticRegression_ovr_liblinear_RandomUnderSampler_costco.png\" width=\"80%\"></img> |\n",
    "| Accuracy | 0.7989 | 0.7404 |\n",
    "| Cross Entropy | 0.5493 | 0.7486 |\n",
    "| Correlation | 0.6679 | 0.8201 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the report consists of the results on various ML predictive modelings we investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### $\\S3.$ Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Logistic Regression.** When we apply logistic regression on the original training data, we get the following results:\n",
    "\n",
    "* Accuracy: $0.7410$ \n",
    "\n",
    "* Cross Entropy: $0.6569$\n",
    "\n",
    "* Correlation: $0.7292$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_NoneType_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "On the other hand, after <u>randomly undersampling</u> all the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6500$\n",
    "\n",
    "* Cross Entropy: $0.9101$\n",
    "\n",
    "* Correlation: $0.8045$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As discussed in Section 2.3, undersampling the data reduces the accuracy, but yields a confusion matrix that has higher values near the diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Random Over-Sampler.** If we initially apply a <u>random over-sampling</u> to the minority classes to a size of 30,000 and <u>randomly undersample</u> the majority classes to 30,000, then we get:\n",
    "\n",
    "* Accuracy: $0.6500$\n",
    "\n",
    "* Cross Entropy: $0.9024$\n",
    "\n",
    "* Correlation: $0.8053$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_RandomOverSampler_30k_RandomUnderSampler_30k_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "This approach has no meaningful difference to only undersampling, and indeed, adding shrinkage to the random over-sampler yielded similar results. On the other hand, most other over-samplers and undersamplers provided in the `imblearn` package has a high computational cost for our data. One solution is to apply principal component analysis to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 PCA with Random Undersampler.** In this section, we analyze the effect of applying principal component analysis (PCA) to the data before randomly undersampling and then applying logistic regression. When we apply PCA to 128 dimensions, we get:\n",
    "\n",
    "* Accuracy: $0.6497$\n",
    "\n",
    "* Cross Entropy: $0.9197$\n",
    "\n",
    "* Correlation: $0.8015$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA128_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "If we train the model on the first 64 principal components, we get\n",
    "\n",
    "* Accuracy: $0.6475$\n",
    "\n",
    "* Cross Entropy: $0.9276$\n",
    "\n",
    "* Correlation: $0.7969$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA64_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "When we use only the first 8 principal components, we get\n",
    "\n",
    "* Accuracy: $0.6353$\n",
    "\n",
    "* Cross Entropy: $0.9633$\n",
    "\n",
    "* Correlation: $0.7860$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA8_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As expected, the performance decreases as we use less principal components. On the other hand, the results are still quite reasonable, which indicates that PCA onto the above dimensions do not lead to a severe loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 PCA with SMOTE.** We analyze the effect of applying more computationally expensive balancing methods after using PCA.\n",
    "\n",
    "Using the first 8 principal components, if we apply Synthetic Minority Over-sampling Technique (SMOTE) to <u>over-sample</u> the minority classes to 100,000 and then <u>randomly undersample</u> the majority classes to 100,000, applying logistic regression gives:\n",
    "\n",
    "* Accuracy: $0.6346$\n",
    "\n",
    "* Cross Entropy: $0.9552$\n",
    "\n",
    "* Correlation: $0.7849$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA8_SMOTE_100k_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Applying SMOTE does not seem to affect the performance in a meaningful way. Other undersampling methods, such as cluster centroids or edited nearest neighbors, took quite long to complete even when only using 8 principal components, so henceforth, we will focus on the random undersampler. However, these other methods should be explored in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S4.$ K-Nearest Neighbors\n",
    "\n",
    "Applying k-nearest neighbors (KNN) to the original dataset is computationally expensive, so we will make use of PCA.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors without balancing the data, we get: \n",
    "\n",
    "* Accuracy: $0.7347$\n",
    "\n",
    "* Cross Entropy: $0.8564$\n",
    "\n",
    "* Correlation: $0.7418$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n50_PCA16_NoneType_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**Remark**. The performance is worse than logistic regression.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors <u>after randomly undersampling</u> the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6062$\n",
    "\n",
    "* Cross Entropy: $1.2505$\n",
    "\n",
    "* Correlation: $0.7924$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n50_PCA16_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Again, the performance is worse than logistic regression. Furthermore, we can see the same pattern where undersampling the data lowers the accuracy but gives a more reasonable confusion matrix.\n",
    "\n",
    "Using the first 128 principal components, if we apply KNN with 200 neighbors <u>after randomly undersampling</u> the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6315$\n",
    "\n",
    "* Cross Entropy: $0.9790$\n",
    "\n",
    "* Correlation: $0.7885$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n200_PCA128_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "During cross-validation, we verified that increasing the number of principal components and the number of neighbors, at least up to 200, seems to increase the accuracy at the cost of computation time. These hyperparameters have not been fully explored, but these results indicate that logistic regression has comparable performance to KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S5.$ Support Vector Machine for Classification\n",
    "\n",
    "SVM is also computationally expensive, so we will employ PCA here as well.\n",
    "\n",
    "Using the first 256 principal components, applying SVM <u>after randomly undersampling</u> gives:\n",
    "\n",
    "* Accuracy: $0.6389$\n",
    "\n",
    "* Cross Entropy: $0.8823$\n",
    "\n",
    "* Correlation: $0.8144$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/SVC_PCA128_RandomUnderSampler_final.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S6.$ XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `XGBClassifier` for all results in this section.\n",
    "\n",
    "**6.1 Before Random Undersampling.**  The XGBoost classifier (with default parameters) performed similarly to the logistic regression:\n",
    "\n",
    "* Accuracy: $0.7402$ \n",
    "\n",
    "* Cross Entropy: $0.6532$\n",
    "\n",
    "* Correlation: $0.7483$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**6.2 After Random Undersampling.**  Also, similarly to logistic regression, <u>random undersampling</u> makes the confusion matrix closer to a diagonal matrix, but significantly increases the misclassification of the majority classes.\n",
    "\n",
    "* Accuracy: $0.6130$\n",
    "\n",
    "* Cross Entropy: $0.9196$\n",
    "\n",
    "* Correlation: $0.7968$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**6.3 Weighting samples.**  Using sample weights has a similar effect to undersampling but with better overall scores:\n",
    "\n",
    "* Accuracy: $0.6464$\n",
    "\n",
    "* Cross Entropy: $0.8502$\n",
    "\n",
    "* Correlation: $0.8010$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_weighted.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**6.4 Hyperparameter tuning.**  Varying column sample size per tree, row subsample ratio, maximum depth, number of trees, minimum child weight, and learning rate did not change any of the scores significantly.\n",
    "\n",
    "* Accuracy: $0.7370$\n",
    "\n",
    "* Cross Entropy: $0.6661$\n",
    "\n",
    "* Correlation: $0.7523$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_optimized.png\" width=\"50%\"></img>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S7.$ Feedforward Neural Network (FNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply FNN with three hidden layers with ReLU activation of the following form:\n",
    "\n",
    "$$\\mathbb{R}^{1024} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{5}.$$\n",
    "\n",
    "We use cross entropy as loss function.\n",
    "\n",
    "**Remark**. We have tried different variations of FNN, but we realized that increasing the complexity of the network, say by increasing the number of hidden layers, did not improve the performance of the model either in training or testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1 Without Undersampling**. To get the model without undersampling, for each fold of 11-folds, we ran two epochs of training with batch size 10. Then we picked the best performing fold in the testing set. The metrics were\n",
    "\n",
    "* Accuracy : $0.7386$\n",
    "\n",
    "* Cross Entropy: $0.6515$\n",
    "\n",
    "* Correlation: $0.7693$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FNN.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**7.2 With Random Undersampling**. After random undersampling, we made a 10:1 train test split on the training data to train the model with validation in training. (There were some technical difficulties in using the random undersampling package and KFold together with FNN.) Then we computed the evaluation metrics on the test data:\n",
    "\n",
    "* Accuracy : $0.6455$\n",
    "\n",
    "* Cross Entropy: $0.9823$\n",
    "\n",
    "* Correlation: $0.8085$\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FNN_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S8.$ Conclusions and Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we used GTE Sentence Transformers to vectorize the text of Google reviews, which we then used to predict the corresponding star rating. Due to the imbalanced nature of our data, accuracy was not deemed to be the best metric to evaluate our models. We instead also consider the cross entropy loss and the normalized correlation of the confusion matrices. Logistic regression, k-nearest neighbors, support vector classification, XGBoost, and feedforward neural networks all had lower cross entropy than the baseline when trained with the original data. We were able to significantly improve the normalized correlation by randomly undersampling the training data. However, across all models, this came with the cost of higher cross entropy and lower accuracy than those obtained by training on the original data. In both approaches, our models perform well--even for data from other sources--without the need to train the vectorization, signicantly reducing the computational cost for users.\n",
    "\n",
    "On the other hand, there are several avenues by which this project can be futher investigated. Firstly, we could consider other metrics that are more suited for imbalanced data, such as the geometric mean or the Area Under the Receiver Operating Characteristic Curve (ROC AUC). Furthermore, we could employ other undersampling or oversampling methods, although many of these come with a significantly higher computational cost than randomly undersampling. The choice of sentence transformer, i.e. using a pre-trained vectorization model other than GTE, could also affect our results. Finally, we could train and test unsupervised models using text data with no ratings, for example, comments on Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"1\">[1]</a> \n",
    "T. Chen, P. Samaranayake, X. Cen, M. Qi, and Y. Lan. (2022). \"**The Impact of Online Reviews on Consumers’ Purchasing Decisions: Evidence From an Eye-Tracking Study**,\" Front Psychol. **13**: 865702.\n",
    "\n",
    "<a id=\"1\">[2]</a> \n",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019). \"**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**,\" Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n",
    "\n",
    "<a id=\"1\">[3]</a> \n",
    "M. S. Kim, K. W. Lee, J. W. Lim, D. H. Kim, and S. Hong. (2023). \"**Ranking Roughly Tourist Destinations Using BERT-Based Semantic Search**\", Shakya, S., Du, KL., Ntalianis, K. (eds) Sentiment Analysis and Deep Learning. Advances in Intelligent Systems and Computing, vol 1432. Springer, Singapore.\n",
    "\n",
    "<a id=\"1\">[4]</a>\n",
    "Jiacheng Li, Jingbo Shang, and Julian McAuley. (2022). \"**UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining**,\" Annual Meeting of the Association for Computational Linguistics (ACL)\n",
    "\n",
    "<a id=\"1\">[5]</a>\n",
    "Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang. (2023).\"**Towards General Text Embeddings with Multi-stage Contrastive Learning**,\" arXiv preprint: https://arxiv.org/abs/2308.03281\n",
    "\n",
    "<a id=\"1\">[6]</a>\n",
    "N. Reimers and I. Gurebych. (2019). \"**Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks**,\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, p.3982–3992, Hong Kong, China, November 3–7, 2019.\n",
    "\n",
    "<a id=\"1\">[7]</a>\n",
    "An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian Mcauley. (2023). \"**Personalized Showcases: Generating Multi-Modal Explanations for Recommendations**,\"The 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)\n",
    "\n",
    "<a id=\"1\">[8]</a>\n",
    "L. Yang, Y. Li, J. Wang, and R. S. Sherratt. (2020). \"**Sentiment Analysis for E-Commerce Product Reviews in Chinese Based on Sentiment Lexicon and Deep Learning**,\" IEEE Access **8**: p.23522-23530.\n",
    "\n",
    "<a id=\"1\">[9]</a>\n",
    "Qiang Ye, R. Law, B. Gu, and W. Chen. (2011). \"**The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings**,\"  Computers in Human Behavior **2**: p.634-639.\n",
    "\n",
    "<a id=\"1\">[10]</a>\n",
    "Zhang and Zhong. (2019). \"**Mining Users Trust From E-Commerce Reviews Based on Sentiment Similarity Analysis**,\" IEEE Access **7**: p.13523-13535.\n",
    "\n",
    "<a id=\"1\">[11]</a>\n",
    "Y. Zhao, L. Wang, H. Tang, and Y. Zhang. (2020). \"**Electronic word-of-mouth and consumer purchase intentions in social e-commerce**,\" Electronic Commerce Research and Applications, **41**: 100980."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
