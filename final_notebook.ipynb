{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Discourse\n",
    "\n",
    "### **Finding Numerical Ratings of Consumer Sentiments using GTE Sentence Trasformer**\n",
    "\n",
    "by Vinicius Ambrosi, Gilyoung Cheong, Dohoon Kim, Hannah Lloyd\n",
    "\n",
    "**Abstract**. There is a wealth of discourse on companies and their products on social media platforms and online forums. While many approaches leverage analytical techniques to gauge audience sentiment through online discourse, they lack the ability to be both targeted and customizable while maintaining complex analytical integrity. In this report, we use Sentence Transformer, the state-of-art text embedding API, with GTE (General Text Embeddings with Multi-stage Contrastive Learning) pretrained model, to vectorize 788,766 comments from Google Reviews into a 1024-dimensional vector space. We then use these vectors as features to train our models and develop rating models that rate a given comment from 1 to 5 stars. Each vector provides 1024 features for a review comment, with the target variable being the rating. We develope our models using Logistic Regression (One vs. Rest), k-Nearest Neigbor, Suppor Vector Machine, XGBoost, and Neural Network with a simple architecture after appropriate train-test splits. To address the biased nature of the training data, which favors 4 or 5-star ratings, we also build our model with random under-sampling. With or without under sampling, we significantly improve baseline model, which always predicts 5 stars. Our experiemental results provide how to use pre-trained Sentence Transformer to extract numerical values of consumer sentiments from online comments without extra cost of pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S1.$ Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online comments and reviews have grown increasingly vital in shaping consumer decisions, particularly in the aftermath of the COVID-19 pandemic. Numerous studies, including those by [[1]](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.865702/full), [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), [[8]](https://ieeexplore.ieee.org/document/8970492), [[9]](https://www.sciencedirect.com/science/article/pii/S0747563210000907), [[10]](https://ieeexplore.ieee.org/document/8631160), and [[11]](https://www.sciencedirect.com/science/article/abs/pii/S1567422320300570) have underscored the significance of analyzing consumer sentiments within the realms of e-commerce and tourism. The importance of these sentiments has been highlighted, showing that understanding consumer feedback can provide valuable insights into market trends and customer preferences. In light of these findings, this report utilizes Natural Language Processing (NLP) and Machine Learning (ML) techniques to construct predictive models capable of assessing and rating comments provided by consumers. By employing these advanced analytical methods, we aim to enhance the correctness and effectiveness of sentiment analysis in understanding and forecasting consumer behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. NLP Methodology: GTE Sentence Transformer**. We use Sentence Transformer, the state-of-the-art text embedding NLP, to vectorize 788,766 pre-processed comments from Google Reviews about a specific business (Costco). These vectors then serve as input features for building predictive models for ratings. The pretrained model for our sentence transformer is GTE (General Text Embeddings with Multi-stage Contrastive Learning) developed by Alibaba Group NLP team in [[5]](https://arxiv.org/abs/2308.03281). The earliest Sentence Transfomer (Sentence-BERT) was was developed as outlined in [[6]](https://arxiv.org/abs/1908.10084) by Reimers and Gurebych and is based on BERT, which stands for Bidirectional Encoder Representations from Transformers, introduced in [[2]](https://arxiv.org/abs/1810.04805) by Google.\n",
    "\n",
    "BERT was revolutionary because it provided vector representations of sentences, with each subword token encoded into a vector that retains its relationship with the entire input context. This contextual awareness enabled BERT to excel in tasks such as question answering, where it generates answers based on user-provided context. \n",
    "\n",
    "However, using BERT for sentence clustering posed challenges because it required providing the full context every time a sentence was vectorized. This limitation made BERT less suitable for building predictive models that need to be tested on unknown data. Additionally, since BERT encodes each subword of a sentence into a vector, a sentence corresponds to a sequence of vectors, not a single vector, which requires significant storage. Various attempts to address these issues involved encoding each sentence without context and using either the encoded vector of the first special token (called the [CLS] token) or the average vector of the sequence of encoded vectors of all the subwords, but these approaches generally lead to poor performance.\n",
    "\n",
    "Sentence Transformers use specific loss functions to train the average BERT-generated vector of subwords of each sentence in the training set so that two semantically similar sentences are associated with two vectors that are close to each other in terms of (Euclidean) distance and angle, the latter of which is measured by cosine similarity. The details of the pre-training and fine-tuning processes of GTE Sentence Transformer are available in Section 3 of [[5]](https://arxiv.org/abs/2308.03281)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. ML Methodology: Logistic Regression, kNN, XGBoost, and FNN**. We use several widely accessible Machine Learning (ML) models to train on the vectors we get from GTE Sentence Transformer on our data so that they can rate a given online comment from 1 to 5 stars to capture consumers' sentiments. Specifically, we use Logistic Regression, k-Nearest Neighbor (kNN), Suppor Vector Machine (SVM), XGBoost, and Feedforward Neural Network (FNN) with three hidden layers and ReLU activation to build our models.\n",
    "\n",
    "**1.3. Data and Variables**. We use [2021 Google Review data](https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/googlelocal/) collected by Li and Zhang for their papers [[4]](https://aclanthology.org/2022.acl-long.426.pdf) and [[7]](https://dl.acm.org/doi/abs/10.1145/3539618.3592036). During our pre-processing, using the Google Maps ID attached to each data point, we extracted 788,766 reviews for Costco from consumers in the United States. We use GTE Sentence Transformer to construct a unique vector for each review comment in $\\mathbb{R}^{1024}$, the real vector space of dimension 1024. Each component of such a vector is used as an input feature for each comment, so a comment gets 1024 input features. The target variable is rating, which is an integer in $\\{1, 2, 3, 4, 5\\}$. The following is the scatter plot of our training set, which is 80% of our data, projected on the first and second principal components:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/PCA picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "For building our models, we first separate training set with test set with the ratio of 8:2. Within the training set, we apply 11-fold cross validation for each ML method when we build our models. (For FFN, the 11-fold cross validation is simplified to another 10:1 train test split.)\n",
    "\n",
    "**1.4. Key Contribution**. Our key contribution is to showcase how the imblanced nature of our data influence various accssible ML models we use in predictive analysis for consumer sentiments when it comes to online reviews. Focusing on the accurcy alone is misleading because our data is highly imbalanced. The following is the histogram for ratings in our testing set:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/Imbalance picture.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Thus, for each predictive modeling, we also build additional model after random-under sampling. As the reader may expect, the overall accuracy drops, but we still get a better cross validation and the confusion matrix is much more convincing.\n",
    "\n",
    "**1.5. Comparing with Preceding Works**. There are have been great interests in analyzing consumers' sentiment, many of which are surveyed by Yang, Li, Wang, and Sherratt in Section II of [[8]](https://ieeexplore.ieee.org/document/8970492). In Section III of their paper, the authors also devleop their own sentiment analysis model by manually identifying (sub)words with positive and negative sentiments to create weights attached to BERT-generated vectors from the comments they pre-train. Then they apply Convolutional Neural Network (CNN) and a modified version of Recurrent Neural Network (RNN) to modify vectors so that they are ideally infludenced by a few words with stong sentiment and remember relationships between words. After that they apply another linear layer with hyperbolic tangent activation followed by SoftMax to get a numerical value between 0 and 1. Then the authors of [[8]](https://ieeexplore.ieee.org/document/8970492) use a real-world data set (in Chinese) with rating to compare their model with the true rating. Their classification is binary by classifying 1 and 2 starts to be positive while 3, 4, and 5 stars to be negative. On the other hand, our approach is greatly simplified thanks to Sentence Transformer, which cuts the pre-training step, and this can be a significant reduction in cost for deployment. \n",
    "\n",
    "In [[3]](https://link.springer.com/chapter/10.1007/978-981-19-5443-6_1), Kim, Lee, Lim, Kim, and Hong also used Senternce Transformer to rank top tourist spots in Busan, South Korea, by measuring cosine similairties between a vector generated by the given query sentence (e.g., \"It is a beautiful beach\") to the vectors generated from online review comments. Two major differences are that\n",
    "\n",
    "1. Kim et al used the model [\"all-MiniLM-L6-v2\"](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) for the sentence transformer, while we use GTE: [\"thenlper/gte-large\"](https://huggingface.co/thenlper/gte-large);\n",
    "2. the input features for Kim et al are generated by the cosine similarities between the comment vectors and a given query vector, while we directly use components of the comment vectors as our input features so that no information is possibly lost after vectorization.\n",
    "\n",
    "In either wrok above, the issue for the imbalance in data is not addressed. Overall, dealing with the imbalanced issue with consumer sentiment analysis is not enoughly addressed in the literature when it comes to consumer sentiment analysis, despite it being a common issue in Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6. Summary of Results**. We use accuracy and cross entropy for evaluation metrics. For an equally probable rating, if we predict one rating at random, we have the following metrics:\n",
    "\n",
    "* Accuracy: $0.2$\n",
    "\n",
    "* Cross Entropy: $-\\log(0.2) \\approx 1.609$.\n",
    "\n",
    "Since our data is highly biased at 5 star rating, the reader must note that even if we consider a model that always predicts 5 star rating from every comment, we get high accuracy, which is equal to the high proportion of 5 star rating. We consider this as our baseline model. The following are the metrics for our <u>baseline</u>:\n",
    "\n",
    "* Accuracy: $0.6694$\n",
    "\n",
    "* Cross Entropy: $1.0877$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The following table compares the results before random undersampling:\n",
    "\n",
    "| No Undersampling | baseline | log reg |   kNN  | XGBoost |   FNN  |\n",
    "|:----------------:|:--------:|:-------:|:------:|:-------:|:------:|\n",
    "|     Accuracy     |  0.6694  | 0.7410  | 0.7346 | 0.7402 | 0.7386 |\n",
    "|   Cross Entropy  |  1.0877  | 0.6575  | 0.8503 | 0.6532 | 0.6515 |\n",
    "\n",
    "**Remark**. kNN is with 50 neighbors and PCA with 16 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The following table compares the results <u>after random undersampling</u>:\n",
    "\n",
    "| Random Undersampling | baseline | log reg |   kNN  |   SVM  | XGBoost |   FNN  |\n",
    "|:--------------------:|:--------:|:-------:|:------:|:------:|:-------:|:------:|\n",
    "|       Accuracy       |  0.6694  |  0.6495 | 0.6298 | 0.6391 |  0.6130 | 0.6455 |\n",
    "|     Cross Entropy    |  1.0877  |  0.9113 | 0.9751 | 0.8844 |  0.9196 | 0.9823 |\n",
    "\n",
    "**Remark**. kNN is with 200 neighbors and PCA with 128 components. SVM is with rbf kernal and PCA with 128 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### $\\S2.$ Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Logistic Regression.** When we apply logistic regression on the original training data, we get, as the average of the 11-fold cross-validation, the following results:\n",
    "\n",
    "* Accuracy: $0.7410$ \n",
    "\n",
    "* Cross Entropy: $0.6575$\n",
    "\n",
    "The accuracy is better than baseline $0.6694$. The cross entropy is also better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_NoneType.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Note that here and henceforth, our confusion matrices are normalized across the rows, i.e. the true labels.\n",
    "\n",
    "On the other hand, after <u>randomly undersampling</u> all the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6495$\n",
    "\n",
    "* Cross Entropy: $0.9113$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As discussed in Section 1.4, undersampling the data reduces the accuracy, but yields a confusion matrix that has higher values near the diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Random oversampler.** If we initially apply a <u>random oversampling</u> to the minority classes to a size of 30,000 and <u>randomly undersample</u> the majority classes to 30,000, then we get:\n",
    "\n",
    "* Accuracy: $0.6496$\n",
    "\n",
    "* Cross Entropy: $0.9039$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_RandomOverSampler_30k_RandomUnderSampler_30k.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "This approach has no meaningful difference to only undersampling, and indeed, adding shrinkage to the random oversampler yielded similar results. On the other hand, most other oversamplers and undersamplers provided in the `imblearn` package has a high computational cost for our data. One solution is to apply principal component analysis to reduce the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 PCA without Balancing.** In this section, we analyze the effect of applying principal component analysis (PCA) to the data before randomly undersampling and then applying logistic regression. When we apply PCA to 128 dimensions, we get:\n",
    "\n",
    "* Accuracy: $0.6492$\n",
    "\n",
    "* Cross Entropy: $0.9213$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "If we train the model on the first 64 principal components, we get\n",
    "\n",
    "* Accuracy: $0.6467$\n",
    "\n",
    "* Cross Entropy: $0.9291$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA64_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "When we use only the first 8 principal components, we get\n",
    "\n",
    "* Accuracy: $0.6345$\n",
    "\n",
    "* Cross Entropy: $0.9642$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA8_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "As expected, the performance does decrease as we use less principal components. On the other hand, the results are still quite reasonable, which indicates that PCA onto the above dimensions do not lead to a severe loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 PCA with Balancing.** We analyze the effect of applying more computationally expensive balancing methods after using PCA.\n",
    "\n",
    "Using the first 8 principal components, if we apply Synthetic Minority Over-sampling Technique (SMOTE) to <u>oversample</u> the minority classes to 100,000 and then <u>randomly undersample</u> the majority classes to 100,000, applying logistic regression gives:\n",
    "\n",
    "* Accuracy: $0.6339$\n",
    "\n",
    "* Cross Entropy: $0.9561$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/LogisticRegression_ovr_liblinear_PCA8_SMOTE_100k_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Applying SMOTE does not seem to affect the performance in a meaningful way. Other undersampling methods, such as Cluster Centroids or Edited Nearest Neighbors, took quite long to complete even when only using 8 principal components, so henceforth, we will focus on the random undersampler. However, these other methods should be explored in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S3.$ K-Nearest Neighbors\n",
    "\n",
    "Applying k-nearest neighbors (KNN) to the original dataset is computationally expensive, so we will make use of PCA.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors without balancing the data, we get: \n",
    "\n",
    "* Accuracy: $0.7346$\n",
    "\n",
    "* Cross Entropy: $0.8503$\n",
    "\n",
    "The accuracy is better than baseline $0.6694$. The cross entropy is also better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n50_PCA16_NoneType.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**Remark**. The performance is worse than logistic regression.\n",
    "\n",
    "Using the first 16 principal components, if we apply KNN with 50 neighbors <u>after randomly undersampling</u> the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6054$\n",
    "\n",
    "* Cross Entropy: $1.2434$\n",
    "\n",
    "The accuracy is worse than baseline $0.6694$ as expected. The cross entropy is also worse than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n50_PCA16_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Again, the performance is worse than logistic regression. Furthermore, we can see the same pattern where undersampling the data lowers the accuracy but gives a more reasonable confusion matrix.\n",
    "\n",
    "Using the first 128 principal components, if we apply KNN with 200 neighbors <u>after randomly undersampling</u> the non-minority classes, we get:\n",
    "\n",
    "* Accuracy: $0.6298$\n",
    "\n",
    "* Cross Entropy: $0.9751$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/KNeighborsClassifier_n200_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "Increasing the number of principal components and the number of neighbors, at least up to 200, seems to increase the accuracy at the cost of computation time. These hyperparameters have not been fully explored, but these results indicate that logistic regression has comparable performance to KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S4.$ Support Vector Machine for Classification\n",
    "\n",
    "SVM is also computationally expensive, so we will employ PCA here as well.\n",
    "\n",
    "Using the first 128 principal components, applying SVM <u>after randomly undersampling</u> gives:\n",
    "\n",
    "* Accuracy: $0.6391$\n",
    "\n",
    "* Cross Entropy: $0.8844$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/SVC_PCA128_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S5.$ XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `XGBClassifier` for all results in this section. More details about training and hyperparameter tuning can be found in the file `xgboost_training.ipynb`.\n",
    "\n",
    "**2.1 Before Random Undersampling.**  The XGBoost classifier (with default parameters) performed similarly to the logistic regression:\n",
    "\n",
    "* Accuracy: $0.7402$ \n",
    "\n",
    "* Cross Entropy: $0.6532$\n",
    "\n",
    "The accuracy is better than baseline $0.6694$. The cross entropy is also better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**2.2 After Random Undersampling.**  Also, similarly to logistic regression, <u>random undersampling</u> makes the confusion matrix closer to a diagonal matrix, but significantly increases misclassification of the majority classes.\n",
    "\n",
    "* Accuracy: $0.6130$\n",
    "\n",
    "* Cross Entropy: $0.9196$\n",
    "\n",
    "The accuracy is worse than baseline $0.6694$. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**2.3 Weighting samples.**  Using sample weights has a similar effect to undersampling but with better overall scores:\n",
    "\n",
    "* Accuracy: $0.6464$\n",
    "\n",
    "* Cross Entropy: $0.8502$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_weighted.png\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "**2.4 Hyperparameter tuning.**  Varying column sample size per tree, row subsample ratio, maximum depth, number of trees, minimum child weight, and learning rate did not change any of the scores significantly.\n",
    "\n",
    "* Accuracy: $0.7370$\n",
    "\n",
    "* Cross Entropy: $0.6661$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/XGBClassifier_optimized.png\" width=\"50%\"></img>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S6.$ Feedforard Neural Network (FNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply FNN with three hidden layers with ReLU activation of the following form:\n",
    "\n",
    "$$\\mathbb{R}^{1024} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{6} \\rightarrow \\mathbb{R}^{5}.$$\n",
    "\n",
    "We use cross entropy as loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Without Undersampling**. To get the model without undersampling,, for each fold of 11-folds, we ran two epochs with batch size 10. Then we picked the best performing fold in the testing set. The metrics were\n",
    "\n",
    "* Accuracy : $0.7386$\n",
    "\n",
    "* Cross Entropy: $0.6515$\n",
    "\n",
    "The accuracy is better than baseline $0.6694$. The cross entropy is also better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FNN.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**4.2 With Random Undersampling**. After random undersampling, we made a 10:1 train test split on the training data to train the model with validation in training. (There were some techincial difficulties in using the random undersampling package and KFold together with FNN.) Then we computed the metrics on the test data:\n",
    "\n",
    "* Accuracy : $0.6455$\n",
    "\n",
    "* Cross Entropy: $0.9823$\n",
    "\n",
    "The accuracy is not better than baseline $0.6694$ as expected, but it is still not too far off. The cross entropy is better than baseline $1.0877$.\n",
    "\n",
    "* Confusion Matrix:\n",
    "\n",
    "<center>\n",
    "<img src=\"images/FNN_RandomUnderSampler.png\" width=\"50%\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "<a id=\"1\">[1]</a> \n",
    "T. Chen, P. Samaranayake, X. Cen, M. Qi, and Y. Lan. (2022). \"**The Impact of Online Reviews on Consumers’ Purchasing Decisions: Evidence From an Eye-Tracking Study**,\" Front Psychol. **13**: 865702.\n",
    "\n",
    "<a id=\"1\">[2]</a> \n",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. (2019). \"**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**,\" Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\n",
    "\n",
    "<a id=\"1\">[3]</a> \n",
    "M. S. Kim, K. W. Lee, J. W. Lim, D. H. Kim, and S. Hong. (2023). \"**Ranking Roughly Tourist Destinations Using BERT-Based Semantic Search**\", Shakya, S., Du, KL., Ntalianis, K. (eds) Sentiment Analysis and Deep Learning. Advances in Intelligent Systems and Computing, vol 1432. Springer, Singapore.\n",
    "\n",
    "<a id=\"1\">[4]</a>\n",
    "Jiacheng Li, Jingbo Shang, and Julian McAuley. (2022). \"**UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining**,\" Annual Meeting of the Association for Computational Linguistics (ACL)\n",
    "\n",
    "<a id=\"1\">[5]</a>\n",
    "Z. Li, X. Zhang, Y. Zhang, D. Long, P. Xie, and M. Zhang. (2023).\"**Towards General Text Embeddings with Multi-stage Contrastive Learning**,\" arXiv preprint: https://arxiv.org/abs/2308.03281\n",
    "\n",
    "<a id=\"1\">[6]</a>\n",
    "N. Reimers and I. Gurebych. (2019). \"**Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks**,\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, p.3982–3992, Hong Kong, China, November 3–7, 2019.\n",
    "\n",
    "<a id=\"1\">[7]</a>\n",
    "An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian Mcauley. (2023). \"**Personalized Showcases: Generating Multi-Modal Explanations for Recommendations**,\"The 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)\n",
    "\n",
    "<a id=\"1\">[8]</a>\n",
    "L. Yang, Y. Li, J. Wang, and R. S. Sherratt. (2020). \"**Sentiment Analysis for E-Commerce Product Reviews in Chinese Based on Sentiment Lexicon and Deep Learning**,\" IEEE Access **8**: p.23522-23530.\n",
    "\n",
    "<a id=\"1\">[9]</a>\n",
    "Qiang Ye, R. Law, B. Gu, and W. Chen. (2011). \"**The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings**,\"  Computers in Human Behavior **2**: p.634-639.\n",
    "\n",
    "<a id=\"1\">[10]</a>\n",
    "Zhang and Zhong. (2019). \"**Mining Users Trust From E-Commerce Reviews Based on Sentiment Similarity Analysis**,\" IEEE Access **7**: p.13523-13535.\n",
    "\n",
    "<a id=\"1\">[11]</a>\n",
    "Y. Zhao, L. Wang, H. Tang, and Y. Zhang. (2020). \"**Electronic word-of-mouth and consumer purchase intentions in social e-commerce**,\" Electronic Commerce Research and Applications, **41**: 100980."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
